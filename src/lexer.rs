#[derive(Debug, PartialEq, Clone)]
pub enum Token {
    String(String), // æ–‡å­—åˆ—
    Number(f64),    // æ•°å€¤
    Bool(bool),     // çœŸå½å€¤
    Null,           // Null
    WhiteSpace,     // ç©ºç™½
    LeftBrace,      // {
    RightBrace,     // }
    LeftBracket,    // [
    RightBracket,   // ]
    Comma,          // ,
    Colon,          // :
}

// JSONã®æ–‡å­—åˆ—ã‚’Parseã—ã¦ Token å˜ä½ã«åˆ†å‰²
pub struct Lexer<'a> {
    /// èª­è¾¼ä¸­ã®å…ˆé ­æ–‡å­—åˆ—ã‚’æŒ‡ã™
    chars: std::iter::Peekable<std::str::Chars<'a>>,
}

/// å­—å¥è§£æä¸­ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼
#[derive(Debug)]
pub struct LexerError {
    /// ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    pub msg: String,
}

impl LexerError {
    fn new(msg: &str) -> LexerError {
        LexerError {
            msg: msg.to_string(),
        }
    }
}

impl<'a> Lexer<'a> {
    /// æ–‡å­—åˆ—ã‚’å—ã‘å–ã‚Š Lexer ã‚’æ¸¡ã™
    pub fn new(input: &str) -> Lexer {
        Lexer {
            chars: input.chars().peekable(),
        }
    }

    /// æ–‡å­—åˆ—ã‚’ Token å˜ä½ã«åˆ†å‰²ã™ã‚‹
    pub fn tokenize(&mut self) -> Result<Vec<Token>, LexerError> {
        let mut tokens = vec![];

        while let Some(token) = self.next_token()? {
            match token {
                // ç©ºç™½ã¯ä»Šå›ã¯æ¨ã¦ã‚‹ãŒãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¨ã—ã¦ä½¿ãˆã‚‹(è¡Œã€åˆ—)
                Token::WhiteSpace => {}
                _ => {
                    tokens.push(token);
                }
            }
        }

        Ok(tokens)
    }

    /// ä¸€æ–‡å­—åˆ†ã ã‘èª­ã¿é€²ã‚ã€tokenã‚’è¿”ã™
    fn next_return_token(&mut self, token: Token) -> Option<Token> {
        self.chars.next();
        Some(token)
    }

    /// æ–‡å­—åˆ—ã‚’èª­ã¿è¾¼ã¿ã€ãƒãƒƒãƒã—ãŸTokenã‚’è¿”ã™
    fn next_token(&mut self) -> Result<Option<Token>, LexerError> {
        // å…ˆé ­ã®æ–‡å­—åˆ—ã‚’èª­ã¿è¾¼ã‚€
        match self.chars.peek() {
            Some(c) => match c {
                c if c.is_whitespace() || *c == '\n' => {
                    Ok(self.next_return_token(Token::WhiteSpace))
                }
                '{' => Ok(self.next_return_token(Token::LeftBrace)),
                '}' => Ok(self.next_return_token(Token::LeftBrace)),
                '[' => Ok(self.next_return_token(Token::LeftBracket)),
                ']' => Ok(self.next_return_token(Token::RightBracket)),
                ',' => Ok(self.next_return_token(Token::Comma)),
                ':' => Ok(self.next_return_token(Token::Colon)),

                // NOTE
                // ä»¥ä¸‹ã®ãƒãƒƒãƒæ¡ä»¶ã¯é–‹å§‹æ–‡å­—ãŒè©²å½“ã™ã‚‹ Token ã®é–‹å§‹æ–‡å­—ãªã‚‰ã€Token ã®æ–‡å­—åˆ—åˆ†ã ã‘èª­ã¿é€²ã‚ã‚‹

                // String ã¯é–‹å§‹æ–‡å­—åˆ— '"'
                // e.g. "togatoga"
                '"' => {
                    self.chars.next();
                    self.parse_string_token()
                }

                // Number ã¯é–‹å§‹æ–‡å­—ãŒ[0-9] or ('+', '-', '.')
                // e.g. 1, -1235, +10, .001
                c if c.is_numeric() || matches!(c, '+' | '-' | '.') => self.parse_number_token(),

                // Boolean ã® true ã®é–‹å§‹æ–‡å­—ã¯ 't'
                't' => self.parse_bool_token(true),

                // Boolean ã® false ã®èŠ±åŒ»å¸«æ–‡å­—ã¯ 'f'
                'f' => self.parse_bool_token(false),

                // Null ã®é–‹å§‹æ–‡å­—ã¯ 'n'
                'n' => self.parse_null_token(),

                // ä¸Šè¨˜ã®ãƒ«ãƒ¼ãƒ«ã«ãƒãƒƒãƒã—ãªã„æ–‡å­—ã¯ã‚¨ãƒ©ãƒ¼
                _ => Err(LexerError::new(&format!("error: an unexpected char {}", c))),
            },
            None => Ok(None),
        }
    }

    /// nullã®æ–‡å­—åˆ—ã‚’parseã™ã‚‹
    fn parse_null_token(&mut self) -> Result<Option<Token>, LexerError> {
        let s = (0..4).filter_map(|_| self.chars.next()).collect::<String>();

        if s == "null" {
            Ok(Some(Token::Null))
        } else {
            Err(LexerError::new(&format!(
                "error: a null value is expected {}",
                s
            )))
        }
    }

    /// (true|false)ã®æ–‡å­—åˆ—ã‚’parseã™ã‚‹
    fn parse_bool_token(&mut self, b: bool) -> Result<Option<Token>, LexerError> {
        if b {
            let s = (0..4).filter_map(|_| self.chars.next()).collect::<String>();

            if s == "true" {
                Ok(Some(Token::Bool(true)))
            } else {
                Err(LexerError::new(&format!(
                    "error: a boolean true is expected {}",
                    s
                )))
            }
        } else {
            let s = (0..5).filter_map(|_| self.chars.next()).collect::<String>();

            if s == "false" {
                Ok(Some(Token::Bool(false)))
            } else {
                Err(LexerError::new(&format!(
                    "error: a boolean false is expected {}",
                    s
                )))
            }
        }
    }

    /// æ•°å­—ã¨ã—ã¦ä½¿ç”¨å¯èƒ½ãªæ–‡å­—ã¾ã§èª­ã¿è¾¼ã‚€ã€‚èª­ã¿è¾¼ã‚“ã æ–‡å­—åˆ—ãŒæ•°å­—(`f64`)ã¨ã—ã¦Parseã«æˆåŠŸã—ãŸå ´åˆTokenã‚’è¿”ã™ã€‚
    fn parse_number_token(&mut self) -> Result<Option<Token>, LexerError> {
        let mut number_str = String::new();

        while let Some(&c) = self.chars.peek() {
            // æ•°å­—ã«ä½¿ã‚ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹æ–‡å­—ã¯èª­ã¿è¾¼ã¿ã€ãã†ã§ã¯ãªã„æ–‡å­—ã®å ´åˆã¯èª­ã¿è¾¼ã¿ã‚’çµ‚äº†ã™ã‚‹
            if c.is_numeric() | matches!(c, '+' | '-' | 'e' | 'E' | '.') {
                self.chars.next();
                number_str.push(c);
            } else {
                break;
            }
        }

        // èª­ã¿è¾¼ã‚“ã æ–‡å­—åˆ—ãŒParseã§ããŸå ´åˆã¯Tokenã‚’è¿”ã™
        match number_str.parse::<f64>() {
            Ok(number) => Ok(Some(Token::Number(number))),
            Err(e) => Err(LexerError::new(&format!("error: {}", e.to_string()))),
        }
    }

    /// çµ‚ç«¯æ–‡å­—'\"'ã¾ã§æ–‡å­—åˆ—ã‚’èª­ã¿è¾¼ã‚€ã€‚UTF-16(\u0000~\uFFFF)ã‚„ç‰¹æ®Šãªã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ–‡å­—(e.g. '\t','\n')ã‚‚è€ƒæ…®ã™ã‚‹
    fn parse_string_token(&mut self) -> Result<Option<Token>, LexerError> {
        let mut utf16: Vec<u16> = vec![];
        let mut result = String::new();

        while let Some(c1) = self.chars.next() {
            match c1 {
                // Escapeã®é–‹å§‹æ–‡å­—
                '\\' => {
                    let c2 = self
                        .chars
                        .next()
                        .ok_or_else(|| LexerError::new("error: a next char is expected"))?;
                    if matches!(c2, '"' | '\\' | '/' | 'b' | 'f' | 'n' | 'r' | 't') {
                        // ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ–‡å­—åˆ—ã®å‡¦ç†
                        // https://www.rfc-editor.org/rfc/rfc8259#section-7
                        // utf-16ã®ãƒãƒƒãƒ•ã‚¡ã‚’æ–‡å­—åˆ—ã«pushã—ã¦ãŠã
                        Self::push_utf16(&mut result, &mut utf16)?;
                        result.push('\\');
                        result.push(c2);
                    } else if c2 == 'u' {
                        // UTF-16
                        // \u0000 ~ \uFFFF
                        // \uã¾ã§èª­ã¿è¾¼ã‚“ã ã®ã§æ®‹ã‚Šã®0000~XXXXã®4æ–‡å­—ã‚’èª­ã¿è¾¼ã‚€
                        // UTF-16ã«é–¢ã—ã¦ã¯ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†ã‚’è¡Œã†
                        let hexs = (0..4)
                            .filter_map(|_| {
                                let c = self.chars.next()?;
                                if c.is_ascii_hexdigit() {
                                    Some(c)
                                } else {
                                    None
                                }
                            })
                            .collect::<Vec<_>>();

                        match u16::from_str_radix(&hexs.iter().collect::<String>(), 16) {
                            Ok(code_point) => utf16.push(code_point),
                            Err(e) => {
                                return Err(LexerError::new(&format!(
                                    "error: a unicode character is expected {}",
                                    e.to_string()
                                )))
                            }
                        };
                    } else {
                        return Err(LexerError::new(&format!(
                            "error: an unexpected escaped char {}",
                            c2
                        )));
                    }
                }
                // æ–‡å­—åˆ—ã®çµ‚ç«¯
                '\"' => {
                    Self::push_utf16(&mut result, &mut utf16)?;
                    return Ok(Some(Token::String(result)));
                }
                // ãã‚Œä»¥å¤–ã®æ–‡å­—åˆ—
                _ => {
                    Self::push_utf16(&mut result, &mut utf16)?;
                    result.push(c1);
                }
            }
        }

        // æ–‡å­—åˆ—ã®çµ‚ç«¯ã§ã‚ã‚‹ '"' ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        Err(LexerError::new(&"error: not close string"))
    }

    /// utf16ã®ãƒãƒƒãƒ•ã‚¡ãŒå­˜åœ¨ã™ã‚‹ãªã‚‰ã°é€£çµã—ã¦ãŠã
    fn push_utf16(result: &mut String, utf16: &mut Vec<u16>) -> Result<(), LexerError> {
        if utf16.is_empty() {
            return Ok(());
        }
        match String::from_utf16(utf16) {
            Ok(utf16_str) => {
                result.push_str(&utf16_str);
                utf16.clear();
            }
            Err(e) => {
                return Err(LexerError::new(&format!("error: {}", e.to_string())));
            }
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_null() {
        let null = "null";
        let tokens = Lexer::new(null).tokenize().unwrap();
        assert_eq!(tokens[0], Token::Null);
    }

    #[test]
    fn test_bool() {
        let false_str: &str = "false";
        let tokens = Lexer::new(false_str).tokenize().unwrap();
        assert_eq!(tokens[0], Token::Bool(false));

        let true_str: &str = "true";
        let tokens = Lexer::new(true_str).tokenize().unwrap();
        assert_eq!(tokens[0], Token::Bool(true));
    }

    #[test]
    fn test_number() {
        let number_strs = [
            ("3", Token::Number(3.0)),
            ("+3", Token::Number(3.0)),
            ("-3", Token::Number(-3.0)),
            ("1e3", Token::Number(1000.0)),
            ("0.3", Token::Number(0.3)),
            (".3", Token::Number(0.3)),
        ];
        number_strs.map(|(input, expect)| {
            let tokens = Lexer::new(input).tokenize().unwrap();
            assert_eq!(tokens[0], expect);
        });

        let tokens = Lexer::new("+-3").tokenize();
        assert!(tokens.is_err());
    }

    #[test]
    fn test_string() {
        let string_strs = [
            ("\"hello world\"", Token::String("hello world".to_string())),
            ("\"ã‚ã„ã†ãˆãŠ\"", Token::String("ã‚ã„ã†ãˆãŠ".to_string())),
            (
                r#""\u3042\u3044\u3046abc""#,
                Token::String("ã‚ã„ã†abc".to_string()),
            ),
            (
                r#""\uD83D\uDE04\uD83D\uDE07\uD83D\uDC7A""#,
                Token::String(r#"ğŸ˜„ğŸ˜‡ğŸ‘º"#.to_string()),
            ),
        ];
        string_strs.map(|(input, expect)| {
            let tokens = Lexer::new(input).tokenize().unwrap();
            assert_eq!(tokens[0], expect);
        });

        let tokens = Lexer::new("\"hello world").tokenize();
        assert!(tokens.is_err());
    }
}
